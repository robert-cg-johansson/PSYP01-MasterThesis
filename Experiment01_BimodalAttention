################################################
### Draft Analysis Code PSYP:01 Experiment 1 ###
################################################

#Set up workspace
setwd("C:/R.working.directory/")
rm(list=ls())

#Packages
library(ggplot2)
library(BayesFactor)
library(sft)
library(rstan)
library(bridgesampling)
library(MASS)

citation("MASS")

####################
# Simulate Dataset #
####################

#Create simulation function for correlated RT and RF data

response_simulation = function(
  trials,
  mean_RT,
  mean_RF,
  sd_RT,
  sd_RF,
  r
){
  responses = mvrnorm(n = trials,
                      mu = c(0, 0),
                      Sigma = matrix(c(1, r,
                                       r, 1), nrow = 2))
  
  RT = responses[,1]*sd_RT+mean_RT
  RF = responses[,2]*sd_RF+mean_RF
  
  
  data = cbind(RT, RF)
  
  return(data)
}


#Set number of trials per condition and simulate data
tpc <- 50

#Soft
S <-  response_simulation(trials = tpc,
                          mean_RT = 430,
                          mean_RF = 16,
                          sd_RT = 90,
                          sd_RF = 2,
                          r = -0.3)

#Loud
L <-  response_simulation(trials = tpc,
                          mean_RT = 360,
                          mean_RF = 17,
                          sd_RT = 90,
                          sd_RF = 2,
                          r = -0.3)
#Dim
D <-  response_simulation(trials = tpc,
                          mean_RT = 480,
                          mean_RF = 15.5,
                          sd_RT = 90,
                          sd_RF = 2,
                          r = -0.3)
#Bright
B <-  response_simulation(trials = tpc,
                          mean_RT = 420,
                          mean_RF = 16.5,
                          sd_RT = 90,
                          sd_RF = 2,
                          r = -0.3)
#Soft + Dim
SD <-  response_simulation(trials = tpc,
                           mean_RT = 390,
                           mean_RF = 17,
                           sd_RT = 90,
                           sd_RF = 2,
                           r = -0.3)
#Soft + Bright
SB <-  response_simulation(trials = tpc,
                           mean_RT = 360,
                           mean_RF = 17.5,
                           sd_RT = 90,
                           sd_RF = 2,
                           r = -0.3)
#Loud + Dim
LD <-  response_simulation(trials = tpc,
                           mean_RT = 350,
                           mean_RF = 18,
                           sd_RT = 90,
                           sd_RF = 2,
                           r = -0.3)
#Loud + Bright
LB <-  response_simulation(trials = tpc,
                           mean_RT = 320,
                           mean_RF = 18.5,
                           sd_RT = 90,
                           sd_RF = 2,
                           r = -0.3)


########################
# Analysis of Variance #
########################

#Create a dataset for unimodal RT ANOVA
data = as.data.frame(c(S[,1], L[,1], D[,1], B[,1]))
signal = c(rep("soft", tpc), rep("loud", tpc), rep("dim", tpc), rep("bright", tpc))
modality = c(rep("auditory", tpc*2), rep("visual", tpc*2))
intensity = c(rep("weak", tpc), rep("strong", tpc), rep("weak", tpc), rep("strong", tpc))
RT.data.unimodal = cbind(data, signal, modality, intensity)
names(RT.data.unimodal) = c("reaction_time", "signal", "modality", "intensity")

#Compute Bayes Factors for unimodal RT data
bayes_factor <- anovaBF(reaction_time ~ modality*intensity, data=RT.data.unimodal)

print(bayes_factor)
bayes_factor@bayesFactor$bf


#Create a dataset for bimodal RT ANOVA
data = as.data.frame(c(SD[,1], LD[,1], SB[,1], LB[,1]))
signal = c(rep("soft+dim", tpc), rep("loud+dim", tpc), rep("soft+bright", tpc), rep("loud+bright", tpc))
loudness = c(rep("soft", tpc), rep("loud", tpc), rep("soft", tpc), rep("loud", tpc))
brightness= c(rep("dim", tpc*2), rep("bright", tpc*2))
RT.data.bimodal = cbind(data, signal, loudness, brightness)
names(RT.data.bimodal) = c("reaction_time","signal", "loudness", "brightness")

#Compute Bayes Factors for bimodal RT data
bayes_factor <- anovaBF(reaction_time ~ loudness*brightness, data=RT.data.bimodal)

print(bayes_factor)
bayes_factor@bayesFactor$bf


#Create a dataset for unimodal RF ANOVA
data = as.data.frame(c(S[,2], L[,2], D[,2], B[,2]))
signal = c(rep("soft", tpc), rep("loud", tpc), rep("dim", tpc), rep("bright", tpc))
modality = c(rep("auditory", tpc*2), rep("visual", tpc*2))
intensity = c(rep("weak", tpc), rep("strong", tpc), rep("weak", tpc), rep("strong", tpc))
RF.data.unimodal = cbind(data, signal, modality, intensity)
names(RF.data.unimodal) = c("response_force", "signal", "modality", "intensity")

#Compute Bayes Factors for unimodal RT data
bayes_factor <- anovaBF(response_force ~ modality*intensity, data=RF.data.unimodal)

print(bayes_factor)
bayes_factor@bayesFactor$bf


#Create a dataset for bimodal RF ANOVA
data = as.data.frame(c(SD[,2], LD[,2], SB[,2], LB[,2]))
signal = c(rep("soft+dim", tpc), rep("loud+dim", tpc), rep("soft+bright", tpc), rep("loud+bright", tpc))
loudness = c(rep("soft", tpc), rep("loud", tpc), rep("soft", tpc), rep("loud", tpc))
brightness= c(rep("dim", tpc*2), rep("bright", tpc*2))
RT.data.bimodal = cbind(data, signal, loudness, brightness)
names(RT.data.bimodal) = c("response_force","signal", "loudness", "brightness")

#Compute Bayes Factors for bimodal RT data
bayes_factor <- anovaBF(response_force ~ loudness*brightness, data=RT.data.bimodal)

print(bayes_factor)
bayes_factor@bayesFactor$bf


#################################
# Inverse Effectiveness Theorem #
#################################

set.seed(12345)

#Create difference scores for the redundancy gain contrast
auditory_gain_contrast <- ((SD[,1]-S[,1]) - (LB[,1]-L[,1]))  
visual_gain_contrast   <- ((SD[,1]-D[,1]) - (LB[,1]-L[,1]))   
#inverse effectiveness predicts these contrasts to be positive

#Standardize data
y <- auditory_gain_contrast  #visual_gain_contrast can liekwise be entered here
#y <- visual_gain_contrast
y <- y/sd(y)
n <- length(y)

print(y)


stancodeHplus <- '
data {
  int<lower=1> n; // number of observations
  vector[n] y; // observations
  real<lower=0> r; // Cauchy prior scale
}
parameters {
  real<lower=0> delta; // constrained to be positive
  real<lower=0> sigma2;// variance parameter
}
model {
  target += cauchy_lpdf(delta | 0, r) - cauchy_lccdf(0 | 0, r); // Cauchy prior on delta
  target += log(1/sigma2); // Jeffreys prior on sigma2
  target += normal_lpdf(y | delta*sqrt(sigma2), sqrt(sigma2));  // likelihood
}
'
stancodeH0 <- '
data {
  int<lower=1> n; // number of observations
  vector[n] y; // observations
}
parameters {
  real<lower=0> sigma2; // variance parameter
}
model {
  target += log(1/sigma2); // Jeffreys prior on sigma2
  target += normal_lpdf(y | 0, sqrt(sigma2)); // likelihood
}
'


# compile and fit model
stanmodelHplus <- stan_model(model_code = stancodeHplus, model_name="stanmodel")
stanmodelH0 <- stan_model(model_code = stancodeH0, model_name="stanmodel")



stanfitHplus <- sampling(stanmodelHplus, data = list(y = y, n = n, r = 1/sqrt(2)),
                         iter = 10000, warmup = 1000, chains = 4,
                         control = list(adapt_delta = .99))

stanfitH0 <- sampling(stanmodelH0, data = list(y = y, n = n),
                      iter = 10000, warmup = 1000, chains = 4, cores = 1,
                      control = list(adapt_delta = .99))

H0 <- bridge_sampler(stanfitH0, silent = TRUE)
Hplus <- bridge_sampler(stanfitHplus, silent = TRUE)

print(Hplus)
print(H0)

H0.error <- error_measures(H0)$percentage
print(H0.error)

Hplus.error <- error_measures(Hplus)$percentage
print(Hplus.error)

BFplus0 <- bf(Hplus, H0)
print(BFplus0)

BFplus0.BayesFactor <- extractBF(ttestBF(y, nullInterval = c(0, Inf)), onlybf = TRUE)[1]

print(BFplus0.BayesFactor)



###########################################
# Survivor and Mean Interaction Contrasts #
###########################################

#Mean and Survivor Function Contrasts + Capacity Analysis as devised by Houpt et al. (2013)
#http://www.indiana.edu/~psymodel/papers/HouBla13.pdf

#Enter unimodal data for UCIP(AND) testing
T1.h <- B[,1]
T1.l <- D[,1]
T2.h <- L[,1]
T2.l <- S[,1]

#Summate RTs
hh <- T1.h + T2.h
hl <- T1.h + T2.l
lh <- T1.l + T2.h
ll <- T1.l + T2.l

#Run the SIC analysis assuming UCIP(AND) architecture
SerialAND <- sic(hh,hl,lh,ll)
SerialAND$SIC
SerialAND$Dominance
SerialAND$positive
SerialAND$negative
SerialAND$MIC
plot(SerialAND$SIC, do.p=FALSE)

#Enter actual data for UCIP(OR) testing
hh <- LB[,1]
hl <- LD[,1]
lh <- SB[,1]
ll <- SD[,1]

#Run the SIC analysis
SerialAND <- sic(hh,hl,lh,ll)
SerialAND$SIC
SerialAND$Dominance
SerialAND$positive
SerialAND$negative
SerialAND$MIC
plot(SerialAND$SIC, do.p=FALSE)

########################
# Capacity coefficient #
########################

###Soft and Dim signals

###AND-coefficient (performance on trials with multiple targets as compared to UCIP(AND) prediction)

#Input single source response times
pa <- S[,1]
ap <- D[,1]

#Input multiple source response time
pp <- SD[,1]

cap <- capacity.and(list(pp, pa, ap), ratio=FALSE)

#Run the capacity analysis
cap$Ctest
plot(cap$Ct, xlim=c(0,1000), ylim=c(0,2), ylab = "C(t)", xlab="t", main="Capacity Coefficient")


###OR-coefficient (performance on trials with multiple targets as compared to UCIP(OR) prediction

#Input single source response times
pa <- S[,1]
ap <- D[,1]

#Input multiple source response time
pp <- SD[,1]

#Run the capacity analysis
cap <- capacity.or(list(pp, pa, ap))
cap$Ctest
plot(cap$Ct, xlim=c(0,1000), ylim=c(0,2), ylab = "C(t)", xlab="t", main="Capacity Coefficient")



###Loud and Bright Signals

###AND-coefficient (performance on trials with multiple targets as compared to UCIP(AND) prediction)

#Input single source response times
pa <- L[,1]
ap <- B[,1]

#Input multiple source response time
pp <- LB[,1]

cap <- capacity.and(list(pp, pa, ap), ratio=FALSE)

#Run the capacity analysis
cap$Ctest
plot(cap$Ct, xlim=c(0,1000), ylim=c(0,2), ylab = "C(t)", xlab="t", main="Capacity Coefficient")


###OR-coefficient (performance on trials with multiple targets as compared to UCIP(OR) prediction

#Input single source response times
pa <- L[,1]
ap <- B[,1]

#Input multiple source response time
pp <- LB[,1]

#Run the capacity analysis
cap <- capacity.or(list(pp, pa, ap))
cap$Ctest
plot(cap$Ct, xlim=c(0,1000), ylim=c(0,2), ylab = "C(t)", xlab="t", main="Capacity Coefficient")

#############################
### Race Model Inequality ###
#############################

#Race Model Inequality for RT distributions as devised by Ulrich et al. (2007) 
#https://link.springer.com/article/10.3758/BF03193160?LI=true

#RMI algorithm kindly translated from MatLab to R by Y. Lin & L. Piwek via StackExchange. 
#https://stats.stackexchange.com/questions/48581/testing-the-race-model-inequality-in-r




#Probspace function based on equation (3) in Ulrich, Miller and Schroter (2007)
probSpace <- function(len){ 
  P <- numeric(len);
  for(i in 1:len){
    P[i] <- (i - .5) / len;
  }
  return(P)
}


##CDF function
cdf.ulrich <- function(data=NULL, maximum=3000){
  # Create a container, whose length is the longest data vector
  # data is the output from `ties` function
  U <- data[,1]
  R <- data[,2]
  C <- data[,3]
  G <- numeric(maximum);
  
  
  # The length of the processed data vector, trimming off ties, if there is any.
  k <- length(U);  # U contains data in millisecond, e.g., 320 ms etc. 
  
  # The last element of the cumulative frequency supposely is the 
  # length of the data vector.
  n <- C[k]
  
  for(i in 1:k) { U[i] <- round(U[i]) }
  
  # from 1 ms to the first value of the data set, their probability should be 0.
  for(t in 1:U[1]) { G[t] <- 0 }   
  
  for(t in U[1]:U[2]){
    G[t] <- ( R[1]/2 + (R[1]+R[2]) / 2*(t-U[1]) / (U[2] - U[1]) ) / n;
  }
  
  for(i in 2:(k-1)){
    for(t in U[i]:U[i+1]){
      G[t] <- (C[i-1] + R[i] / 2+(R[i] +R[i+1]) / 2*(t-U[i]) / (U[i+1] - U[i])) / n;
    }
  }
  
  for(t in U[k]:maximum){
    G[t] <- 1;
  }
  return(G)
}

##ties function
ties <- function(W){
  # Count number k of unique values
  # and store these values in U.
  U <- NULL; W <- sort(W); n = length(W); k = 1; U[1] <- W[1]
  for (i in 2:n) {
    if (W[i] != W[i-1]) {
      k <- k+1;
      U <- cbind(U, W[i])
    }
  }
  U <- U[1,]
  
  # Determine number of replications R
  # k is the length of the vector, after trimming off the ties
  R <- numeric(k) 
  for (i in 1:k){
    for (j in 1:n){
      if (U[i] == W[j]) R[i] <- R[i] + 1;
    }
  }
  
  # Determine the cumlative frequency
  C <- numeric(k) 
  C[1] <- R[1]
  for(i in 2:k){
    C[i] <- C[i-1] + R[i];
  }
  res <- list(U, R, C)
  names(res) <- c("U", "R", "C")
  return(as.data.frame(res))
}
##Get percentile function
GetPercentile <- function( P, G, tmax ){
  # Determine minimum of |G(Tp[i]) - P[i]|
  np <- length(P);
  Tp <- numeric(np)
  for( i in 1:np) {
    cc <- 100;
    for(t in 1:tmax) {
      if ( abs(G[t] - P[i]) < cc ) {
        c <- t;
        cc <- abs(G[t] - P[i]);
      }
    }
    
    if( P[i] > G[c] ){
      Tp[i] <-  c + (P[i] - G[c]) / (G[c+1] - G[c]);
    } else {
      Tp[i] <- c + (P[i] - G[c]) / (G[c] - G[c-1]);
    }
  }
  return( Tp )
}


##Compute and plot
# cx=channel 1, cy=channel 2, cz=redundant trials

#Soft and Dim signals
cx <- S[,1]
cy <- D[,1]
cz <- SD[,1]


#Loud and Bright signals
cx <-L[,1]
cy <- B[,1]
cz <-LB[,1]

psq <- probSpace(10); psq

dfx <- ties(cx)
dfy <- ties(cy)
dfz <- ties(cz)
tmax <- max(cx,cy,cz)

gx <- cdf.ulrich(data=dfx, maximum=tmax)
gy <- cdf.ulrich(data=dfy, maximum=tmax)
gz <- cdf.ulrich(data=dfz, maximum=tmax)

b <- gx + gy
xp <- GetPercentile(psq, gx, tmax)
yp <- GetPercentile(psq, gy, tmax)
zp <- GetPercentile(psq, gz, tmax);
bp <- GetPercentile(psq, b, tmax);

gdf <- data.frame(RT =c(xp,yp,zp,bp), Probability =rep(psq, 4),
                  Condition =rep(c("Soft", "Dim","Soft+Dim","Bounding sum"), each=length(xp)))
panelf <- ggplot(gdf, aes(x = RT, y = Probability, group=Condition,
                          colour=Condition, shape=Condition)) + 
  geom_point() + geom_line() 
panelf + coord_cartesian(xlim = c(100, 750), ylim=c(-.01,1.01)) +
  theme(legend.position= c(.85, .20),  
        legend.title = element_text(size=12),
        legend.text = element_text(size=12))
zp <- GetPercentile(psq, gz, tmax);
bp <- GetPercentile(psq, b, tmax);

#######################################
### Race Model Inequality (RF Data) ###
#######################################

#The same functions defined for the RT RMI test can be used here
cx <- S[,2]
cy <- D[,2]
cz <- SD[,2]

cx <- L[,2]   #Strong signal energies can elso be entered here
cy <- B[,2]
cz <- LB[,2]
   
psq <- probSpace(10); psq

dfx <- ties(cx)
dfy <- ties(cy)
dfz <- ties(cz)
tmax <- max(cx,cy,cz)

gx <- cdf.ulrich(data=dfx, maximum=tmax)
gy <- cdf.ulrich(data=dfy, maximum=tmax)
gz <- cdf.ulrich(data=dfz, maximum=tmax)

b <- gx + gy
xp <- GetPercentile(psq, gx, tmax)
yp <- GetPercentile(psq, gy, tmax)
zp <- GetPercentile(psq, gz, tmax);
bp <- GetPercentile(psq, b, tmax);

gdf <- data.frame(RT =c(xp,yp,zp,bp), Probability =rep(psq, 4),
                  Condition =rep(c("Soft", "Dim","Soft+Dim","Bounding sum"), each=length(xp)))
panelf <- ggplot(gdf, aes(x = RT, y = Probability, group=Condition,
                          colour=Condition, shape=Condition)) + 
  geom_point() + geom_line() 
panelf + coord_cartesian(xlim = c(10, 20), ylim=c(-.01,1.01)) +
  theme(legend.position= c(.85, .20),  
        legend.title = element_text(size=12),
        legend.text = element_text(size=12))
zp <- GetPercentile(psq, gz, tmax);
bp <- GetPercentile(psq, b, tmax);
